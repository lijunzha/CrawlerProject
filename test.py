import requests
import lxml.etree
# start_url = 'http://140.143.192.76:8002/2018USNEWS%E4%B8%96%E7%95%8C%E5%A4%A7%E5%AD%A6%E6%8E%92%E5%90%8D'
# response = requests.get(start_url)
# links = response.xpath('//*[@id="content"]/table/tbody/tr/td[2]/a/@href').extract()
# print(links)

# response = requests.get('http://140.143.192.76:8002/哈佛大学')
# # print(response)
# print('-------------------')
# # print(response.text)
# print('~~~~~~~~~~~~~~~~~~')
# dom2 = lxml.etree.HTML(response.text)
# # print(dom2)
# wiki = dom2.xpath('//div[@id="wikiContent"]')[0]
# # print(wiki)
# name = wiki.xpath('./h1[@class="wikiTitle"]/text()')[0]
# print(name)
# key = wiki.xpath('./div[@class="infobox"]/table/tbody/tr/td[1]/p/text()')
# value = wiki.xpath('./div[@class="infobox"]/table/tbody/tr/td[2]/p/text()')
# info = dict(zip(key,value))
# print(info)


# from w3lib.html import remove_tags
# s ='<p><a href="xxxxxxxx">abc</a>123</p>'
# s0 = remove_tags(s,keep=('p'))    # 保留p标签
# s1 =remove_tags(s,which_ones=('a'))   # 去掉a标签
# print(s0)
# print(s1)

print('lizihao')
